<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
<title>Index. rspark 0.1.14</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="author" content="">

<link href="css/bootstrap.css" rel="stylesheet">
<link href="css/bootstrap-responsive.css" rel="stylesheet">
<link href="css/highlight.css" rel="stylesheet">
<link href="css/staticdocs.css" rel="stylesheet">

<!--[if lt IE 9]>
  <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
  </head>

  <body>
    <div class="navbar">
  <div class="navbar-inner">
    <div class="container">
      <a class="brand" href="#">rspark 0.1.14</a>
      <div class="nav">
        <ul class="nav">
          <li><a href="index.html"><i class="icon-home icon-white"></i> Index</a></li>
        </ul>
      </div>
    </div>
  </div>
</div>

    <div class="container">
      <header>
        
      </header>
      
      <div class="row">
  <div class="span8">
   
    <h3>Connecting to Spark</h3>
    <p>Functions for installing Spark components and connecting to Spark clusters.</p>

    
    <ul class="index">
        
      <li>
        <code><a href="spark_connect.html">spark_connect</a></code><br />Connects to Spark and establishes the Spark Context</li>
    
    </ul>
    <h3>Reading and Writing Data</h3>
    <p>Functions for reading and writing Spark data frames</p>

    
    <ul class="index">

    </ul>
    <h3>Other</h3>
    
    
    <ul class="index">
        
      <li>
        <code><a href="as_spark_dataframe.html">as_spark_dataframe</a></code><br />Convert a tbl to a Spark Dataset.</li>
            
      <li>
        <code><a href="copy_to.src_spark.html">copy_to.src_spark</a></code><br />Copies the source data frame into a Spark table</li>
            
      <li>
        <code><a href="db_data_type.src_spark.html">db_data_type.src_spark</a></code><br />This operation is currently not supported in Spark</li>
            
      <li>
        <code><a href="dbi-spark-table.html">dbi-spark-table</a></code>(dbExistsTable,DBISparkConnection,character-method, dbListTables,DBISparkConnection-method, dbReadTable,DBISparkConnection,character-method, dbRemoveTable,DBISparkConnection,character-method, dbWriteTable,DBISparkConnection-method, mutate_.tbl_spark)<br />DBI Spark Table</li>
            
      <li>
        <code><a href="dbSetProperty.html">dbSetProperty</a></code><br />Sets a property for the connection</li>
            
      <li>
        <code><a href="dbSetProperty-DBISparkConnection-character-character-method.html">dbSetProperty,DBISparkConnection,character,character-method</a></code><br />Sets a property for the connection</li>
            
      <li>
        <code><a href="dplyr-spark-data.html">dplyr-spark-data</a></code>(load_csv, load_json, load_parquet, save_csv, save_json, save_parquet)<br />Loads a CSV file and provides a data source compatible with dplyr</li>
            
      <li>
        <code><a href="dplyr-spark-table.html">dplyr-spark-table</a></code>(collect.tbl_spark, sample_frac.tbl_spark, sample_n.tbl_spark, sql_build.tbl_spark)<br />Dplyr table definitions for Spark</li>
            
      <li>
        <code><a href="ec2-spark.html">ec2-spark</a></code>(spark_ec2_cluster, spark_ec2_deploy, spark_ec2_destroy, spark_ec2_login, spark_ec2_master, spark_ec2_rstudio, spark_ec2_start, spark_ec2_stop, spark_ec2_web)<br />Install an EC2 Spark cluster</li>
            
      <li>
        <code><a href="ml_kmeans.html">ml_kmeans</a></code><br />Computes kmeans from a dplyr source</li>
            
      <li>
        <code><a href="ml_linear_regression.html">ml_linear_regression</a></code><br />Linear regression from a dplyr source</li>
            
      <li>
        <code><a href="ml_logistic_regression.html">ml_logistic_regression</a></code><br />Logistic regression from a dplyr source</li>
            
      <li>
        <code><a href="ml_pca.html">ml_pca</a></code><br />Perform Principal Components Analaysis using spark.ml</li>
            
      <li>
        <code><a href="ml_random_forest.html">ml_random_forest</a></code><br />Random Forests with Spark ML</li>
            
      <li>
        <code><a href="partition.html">partition</a></code><br />Partition a Spark Dataframe</li>
            
      <li>
        <code><a href="print.jobj.html">print.jobj</a></code><br />Print a JVM object reference.</li>
            
      <li>
        <code><a href="print.src_spark.html">print.src_spark</a></code><br />Prints information associated to the dplyr source</li>
            
      <li>
        <code><a href="spark_can_install.html">spark_can_install</a></code><br />Check if Spark can be installed in this system</li>
            
      <li>
        <code><a href="spark_config.html">spark_config</a></code><br />Defines a configuration file based on the config package and built-in defaults</li>
            
      <li>
        <code><a href="spark_connection_app_name.html">spark_connection_app_name</a></code><br />Retrieves the application name from a Spark Connection</li>
            
      <li>
        <code><a href="spark_connection_is_local.html">spark_connection_is_local</a></code><br />TRUE if the Spark Connection is a local install</li>
            
      <li>
        <code><a href="spark_connection_is_open.html">spark_connection_is_open</a></code><br />Checks to see if the connection into Spark is still open</li>
            
      <li>
        <code><a href="spark_connection_local_cores.html">spark_connection_local_cores</a></code><br />Number of cores available in the local install</li>
            
      <li>
        <code><a href="spark_connection_on_reconnect.html">spark_connection_on_reconnect</a></code><br />Provides an extension mechanism to allow package builders to support spark_connect(reconnect = TRUE)</li>
            
      <li>
        <code><a href="spark_context.html">spark_context</a></code><br />Retrieves the SparkContext reference from a Spark Connection</li>
            
      <li>
        <code><a href="spark_context_master.html">spark_context_master</a></code>(spark_connection_master)<br />Retrieves master from a Spark Connection</li>
            
      <li>
        <code><a href="spark_dataframe_collect.html">spark_dataframe_collect</a></code><br />Read a Spark Dataset into R.</li>
            
      <li>
        <code><a href="spark_dataframe_split.html">spark_dataframe_split</a></code><br />Split a Spark DataFrame</li>
            
      <li>
        <code><a href="spark_disconnect.html">spark_disconnect</a></code><br />Disconnects from Spark and terminates the running application</li>
            
      <li>
        <code><a href="spark_disconnect_all.html">spark_disconnect_all</a></code><br />Closes all existing connections. Returns the total of connections closed.</li>
            
      <li>
        <code><a href="spark_install.html">spark_install</a></code><br />Provides support to download and install the given Spark version</li>
            
      <li>
        <code><a href="spark_install_available.html">spark_install_available</a></code><br />Check if the given Spark version is available in this system</li>
            
      <li>
        <code><a href="spark_install_tar.html">spark_install_tar</a></code><br />Provides support to install a version of Spark from a given TAR file</li>
            
      <li>
        <code><a href="spark_invoke.html">spark_invoke</a></code><br />Executes a method on the given object</li>
            
      <li>
        <code><a href="spark_invoke_static.html">spark_invoke_static</a></code><br />Executes an static method on the given object</li>
            
      <li>
        <code><a href="spark_invoke_static_ctor.html">spark_invoke_static_ctor</a></code><br />Executes an static method on the given object</li>
            
      <li>
        <code><a href="spark_log.html">spark_log</a></code>(print.spark_log, spark_log_file)<br />Retrieves the last n entries in the Spark log</li>
            
      <li>
        <code><a href="spark_sql.html">spark_sql</a></code><br />Executes arbitrary SQL statements</li>
            
      <li>
        <code><a href="spark_versions.html">spark_versions</a></code><br />Retrieves available versions of Spark</li>
            
      <li>
        <code><a href="spark_versions_info.html">spark_versions_info</a></code><br />Retrieves component information for the given Spark and Hadoop versions</li>
            
      <li>
        <code><a href="spark_web.html">spark_web</a></code><br />Opens the Spark web interface</li>
            
      <li>
        <code><a href="spark-transactions.html">spark-transactions</a></code>(dbBegin,DBISparkConnection-method, dbCommit,DBISparkConnection-method, dbRollback,DBISparkConnection-method)<br />Spark Transactions.</li>
            
      <li>
        <code><a href="sql_analyze.src_spark.html">sql_analyze.src_spark</a></code><br />This operation is currently not supported in Spark</li>
            
      <li>
        <code><a href="sql_begin.src_spark.html">sql_begin.src_spark</a></code><br />This operation is currently not supported in Spark</li>
            
      <li>
        <code><a href="sql_commit.src_spark.html">sql_commit.src_spark</a></code><br />This operation is currently not supported in Spark</li>
            
      <li>
        <code><a href="sql_create_index.src_spark.html">sql_create_index.src_spark</a></code><br />This operation is currently not supported in Spark</li>
            
      <li>
        <code><a href="sql_create_table.src_spark.html">sql_create_table.src_spark</a></code><br />This operation is currently not supported in Spark</li>
            
      <li>
        <code><a href="sql_drop_table.src_spark.html">sql_drop_table.src_spark</a></code><br />Removes a Spark table</li>
            
      <li>
        <code><a href="sql_insert_into.src_spark.html">sql_insert_into.src_spark</a></code><br />This operation is currently not supported in Spark</li>
            
      <li>
        <code><a href="sql_rollback.src_spark.html">sql_rollback.src_spark</a></code><br />This operation is currently not supported in Spark</li>
            
      <li>
        <code><a href="src_context.html">src_context</a></code><br />Retrieves the Spark connection object from a given dplyr src</li>
            
      <li>
        <code><a href="src_spark.html">src_spark</a></code><br />Connect to Spark for Dplyr.</li>
            
      <li>
        <code><a href="tbl_cache.html">tbl_cache</a></code><br />Loads a table into memory</li>
            
      <li>
        <code><a href="tbl_uncache.html">tbl_uncache</a></code><br />Unloads table from memory</li>
    
    </ul>
  </div>
  
</div>
      
      <footer>
      
      </footer>
    </div>
  </body>
</html>